{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":18648,"databundleVersionId":1026645,"sourceType":"competition"}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        pass\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-13T17:15:54.078079Z","iopub.execute_input":"2024-09-13T17:15:54.078756Z","iopub.status.idle":"2024-09-13T17:15:56.543626Z","shell.execute_reply.started":"2024-09-13T17:15:54.078716Z","shell.execute_reply":"2024-09-13T17:15:56.542792Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# 결과값 고정을 위한 것\n\nimport torch\nimport random\nimport numpy as np\nimport os\n\nseed = 50\nos.environ['PYTHONASHSEED'] = str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed) # CPU - seed\ntorch.cuda.manual_seed(seed) # GPU - seed\ntorch.cuda.manual_seed_all(seed) # MultiGPU - seed\ntorch.backends.cudnn.deterministic = True # 확정 연산\ntorch.backends.cudnn.benchmark = False # 벤치마크 해제\ntorch.backends.cudnn.enabled = False # cudnn 해제","metadata":{"execution":{"iopub.status.busy":"2024-09-13T17:15:56.545486Z","iopub.execute_input":"2024-09-13T17:15:56.545887Z","iopub.status.idle":"2024-09-13T17:15:56.555451Z","shell.execute_reply.started":"2024-09-13T17:15:56.545843Z","shell.execute_reply":"2024-09-13T17:15:56.554567Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-09-13T17:15:56.556790Z","iopub.execute_input":"2024-09-13T17:15:56.559139Z","iopub.status.idle":"2024-09-13T17:15:56.566831Z","shell.execute_reply.started":"2024-09-13T17:15:56.557064Z","shell.execute_reply":"2024-09-13T17:15:56.566014Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\n\ndata_path = \"/kaggle/input/plant-pathology-2020-fgvc7/\"\n\ntrain = pd.read_csv(data_path + 'train.csv')\ntest = pd.read_csv(data_path + 'test.csv')\nsubmission = pd.read_csv(data_path + 'sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-09-13T17:15:56.568997Z","iopub.execute_input":"2024-09-13T17:15:56.569337Z","iopub.status.idle":"2024-09-13T17:15:56.601686Z","shell.execute_reply.started":"2024-09-13T17:15:56.569304Z","shell.execute_reply":"2024-09-13T17:15:56.600697Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain, valid = train_test_split(train,\n                                test_size=0.1,\n                                stratify=train[['healthy', 'multiple_diseases','rust','scab']],\n                                random_state=50)","metadata":{"execution":{"iopub.status.busy":"2024-09-13T17:15:56.602983Z","iopub.execute_input":"2024-09-13T17:15:56.603299Z","iopub.status.idle":"2024-09-13T17:15:56.629932Z","shell.execute_reply.started":"2024-09-13T17:15:56.603265Z","shell.execute_reply":"2024-09-13T17:15:56.629072Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"import cv2\nfrom torch.utils.data import Dataset\n\nclass ImageDataset(Dataset):\n    # 초기화 메서드(생성자)\n    def __init__(self, df, img_dir='./', transform=None, is_test=False):\n        super().__init__() # 상속받은 Dataset의 __init__() 메서드 호출\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n        self.is_test = is_test\n    \n    # 데이터셋 크기 반환 메서드 \n    def __len__(self):\n        return len(self.df)\n    \n    # 인덱스(idx)에 해당하는 데이터 반환 메서드\n    def __getitem__(self, idx):\n        img_id = self.df.iloc[idx, 0]             # 이미지 ID\n        img_path = self.img_dir + img_id + '.jpg' # 이미지 파일 경로\n        image = cv2.imread(img_path)              # 이미지 파일 읽기\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # 이미지 색상 보정\n        # 이미지 변환 \n        if self.transform is not None:\n            image = self.transform(image=image)['image']\n        # 테스트 데이터면 이미지 데이터만 반환, 그렇지 않으면 타깃값도 반환 \n        if self.is_test:\n            return image # 테스트용일 때\n        else:\n            # 타깃값 4개 중 가장 큰 값의 인덱스 \n            label = np.argmax(self.df.iloc[idx, 1:5]) \n            return image, label # 훈련/검증용일 때","metadata":{"execution":{"iopub.status.busy":"2024-09-13T17:15:56.631357Z","iopub.execute_input":"2024-09-13T17:15:56.631810Z","iopub.status.idle":"2024-09-13T17:15:56.642109Z","shell.execute_reply.started":"2024-09-13T17:15:56.631755Z","shell.execute_reply":"2024-09-13T17:15:56.641086Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"import albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\ntransform_train = A.Compose([\n    A.Resize(450, 650),\n    A.RandomBrightnessContrast(brightness_limit=0.2,\n                              contrast_limit=0.2, p=0.3),\n    A.VerticalFlip(p=0.2),\n    A.HorizontalFlip(p=0.5),\n    A.ShiftScaleRotate(\n    shift_limit=0.1,\n    scale_limit=0.2,\n    rotate_limit=30,\n    p=0.3),\n    A.OneOf([A.Emboss(p=1),\n            A.Sharpen(p=1),\n            A.Blur(p=1)], p = 0.3),\n    A.ElasticTransform(p=0.3), # PieceWiseAffine 대체\n    A.Normalize(),\n    ToTensorV2()\n])","metadata":{"execution":{"iopub.status.busy":"2024-09-13T17:15:56.643371Z","iopub.execute_input":"2024-09-13T17:15:56.643727Z","iopub.status.idle":"2024-09-13T17:15:56.657119Z","shell.execute_reply.started":"2024-09-13T17:15:56.643686Z","shell.execute_reply":"2024-09-13T17:15:56.656174Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"transform_test = A.Compose([\n    A.Resize(450, 650),\n    A.Normalize(),\n    ToTensorV2()\n])","metadata":{"execution":{"iopub.status.busy":"2024-09-13T17:15:56.658547Z","iopub.execute_input":"2024-09-13T17:15:56.659341Z","iopub.status.idle":"2024-09-13T17:15:56.666122Z","shell.execute_reply.started":"2024-09-13T17:15:56.659307Z","shell.execute_reply":"2024-09-13T17:15:56.665188Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"img_dir = '/kaggle/input/plant-pathology-2020-fgvc7/images/'\n\ndataset_train = ImageDataset(train, img_dir=img_dir, transform=transform_train)\ndataset_valid = ImageDataset(valid, img_dir=img_dir, transform=transform_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-13T17:15:56.667106Z","iopub.execute_input":"2024-09-13T17:15:56.667393Z","iopub.status.idle":"2024-09-13T17:15:56.676983Z","shell.execute_reply.started":"2024-09-13T17:15:56.667361Z","shell.execute_reply":"2024-09-13T17:15:56.676000Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"### 멀티프로세싱","metadata":{}},{"cell_type":"code","source":"def seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n    \ng = torch.Generator()\ng.manual_seed(0)","metadata":{"execution":{"iopub.status.busy":"2024-09-13T17:15:56.680859Z","iopub.execute_input":"2024-09-13T17:15:56.681218Z","iopub.status.idle":"2024-09-13T17:15:56.688858Z","shell.execute_reply.started":"2024-09-13T17:15:56.681183Z","shell.execute_reply":"2024-09-13T17:15:56.687900Z"},"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x78cc8a1b9510>"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nbatch_size = 4\n\nloader_train = DataLoader(dataset_train, batch_size=batch_size,\n                         shuffle=True, worker_init_fn=seed_worker,\n                         generator=g, num_workers=2)\n\nloader_valid = DataLoader(dataset_valid, batch_size=batch_size,\n                         shuffle=False, worker_init_fn=seed_worker,\n                         generator=g, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2024-09-13T17:15:56.690037Z","iopub.execute_input":"2024-09-13T17:15:56.690578Z","iopub.status.idle":"2024-09-13T17:15:56.697717Z","shell.execute_reply.started":"2024-09-13T17:15:56.690535Z","shell.execute_reply":"2024-09-13T17:15:56.696905Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"!pip install efficientnet-pytorch==0.7.1","metadata":{"execution":{"iopub.status.busy":"2024-09-13T17:15:56.698869Z","iopub.execute_input":"2024-09-13T17:15:56.699255Z","iopub.status.idle":"2024-09-13T17:16:09.527272Z","shell.execute_reply.started":"2024-09-13T17:15:56.699214Z","shell.execute_reply":"2024-09-13T17:16:09.526101Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"Requirement already satisfied: efficientnet-pytorch==0.7.1 in /opt/conda/lib/python3.10/site-packages (0.7.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1) (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from efficientnet_pytorch import EfficientNet\n\nmodel = EfficientNet.from_pretrained('efficientnet-b7', num_classes=4)\n\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-13T17:16:09.528945Z","iopub.execute_input":"2024-09-13T17:16:09.529365Z","iopub.status.idle":"2024-09-13T17:16:10.545749Z","shell.execute_reply.started":"2024-09-13T17:16:09.529328Z","shell.execute_reply":"2024-09-13T17:16:10.544722Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"Loaded pretrained weights for efficientnet-b7\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.nn as nn\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.00006, weight_decay=0.0001)","metadata":{"execution":{"iopub.status.busy":"2024-09-13T17:16:10.547072Z","iopub.execute_input":"2024-09-13T17:16:10.547403Z","iopub.status.idle":"2024-09-13T17:16:10.568394Z","shell.execute_reply.started":"2024-09-13T17:16:10.547370Z","shell.execute_reply":"2024-09-13T17:16:10.567533Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score # ROC AUC 점수 계산 함수\nfrom tqdm.notebook import tqdm # 진행률 표시 막대 \n\nepochs = 5\n\n# 총 에폭만큼 반복\nfor epoch in range(epochs):\n    # == [ 훈련 ] ==============================================\n    model.train()        # 모델을 훈련 상태로 설정 \n    epoch_train_loss = 0 # 에폭별 손실값 초기화 (훈련 데이터용)\n    \n    # '반복 횟수'만큼 반복 \n    for images, labels in tqdm(loader_train):\n        # 이미지, 레이블(타깃값) 데이터 미니배치를 장비에 할당 \n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # 옵티마이저 내 기울기 초기화\n        optimizer.zero_grad()\n        # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n        outputs = model(images)\n        # 손실 함수를 활용해 outputs와 labels의 손실값 계산\n        loss = criterion(outputs, labels)\n        # 현재 배치에서의 손실 추가 (훈련 데이터용)\n        epoch_train_loss += loss.item() \n        loss.backward() # 역전파 수행\n        optimizer.step() # 가중치 갱신\n    # 훈련 데이터 손실값 출력\n    print(f'에폭 [{epoch+1}/{epochs}] - 훈련 데이터 손실값 : {epoch_train_loss/len(loader_train):.4f}')\n    \n    # == [ 검증 ] ==============================================\n    model.eval()          # 모델을 평가 상태로 설정 \n    epoch_valid_loss = 0  # 에폭별 손실값 초기화 (검증 데이터용)\n    preds_list = []       # 예측 확률값 저장용 리스트 초기화 \n    true_onehot_list = [] # 실제 타깃값 저장용 리스트 초기화 \n    \n    with torch.no_grad(): # 기울기 계산 비활성화\n        # 미니배치 단위로 검증\n        for images, labels in loader_valid:\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            epoch_valid_loss += loss.item()\n            \n            preds = torch.softmax(outputs.cpu(), dim=1).numpy() # 예측 확률값\n            # 실제값 (원-핫 인코딩 형식)\n            true_onehot = torch.eye(4, device=device)[labels].cpu().numpy()\n            # 예측 확률값과 실제값 저장\n            preds_list.extend(preds)\n            true_onehot_list.extend(true_onehot)\n    # 검증 데이터 손실값 및 ROC AUC 점수 출력 \n    print(f'에폭 [{epoch+1}/{epochs}] - 검증 데이터 손실값 : {epoch_valid_loss/len(loader_valid):.4f} / 검증 데이터 ROC AUC : {roc_auc_score(true_onehot_list, preds_list):.4f}')  ","metadata":{"execution":{"iopub.status.busy":"2024-09-13T17:28:57.194258Z","iopub.execute_input":"2024-09-13T17:28:57.195335Z","iopub.status.idle":"2024-09-13T18:06:13.585269Z","shell.execute_reply.started":"2024-09-13T17:28:57.195282Z","shell.execute_reply":"2024-09-13T18:06:13.583974Z"},"trusted":true},"execution_count":70,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/410 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64c949af683c46b79f12c3ecc4b1145d"}},"metadata":{}},{"name":"stdout","text":"에폭 [1/5] - 훈련 데이터 손실값 : 0.3405\n에폭 [1/5] - 검증 데이터 손실값 : 0.2043 / 검증 데이터 ROC AUC : 0.9742\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/410 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9659e5c5da044b2c922a38714d69815b"}},"metadata":{}},{"name":"stdout","text":"에폭 [2/5] - 훈련 데이터 손실값 : 0.2319\n에폭 [2/5] - 검증 데이터 손실값 : 0.1822 / 검증 데이터 ROC AUC : 0.9623\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/410 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40fa930018044b5ea437aee3665648c9"}},"metadata":{}},{"name":"stdout","text":"에폭 [3/5] - 훈련 데이터 손실값 : 0.1548\n에폭 [3/5] - 검증 데이터 손실값 : 0.2823 / 검증 데이터 ROC AUC : 0.9774\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/410 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"690d9ab56db34f8ea973454bedbddd5d"}},"metadata":{}},{"name":"stdout","text":"에폭 [4/5] - 훈련 데이터 손실값 : 0.1225\n에폭 [4/5] - 검증 데이터 손실값 : 0.1809 / 검증 데이터 ROC AUC : 0.9743\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/410 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"796a24ef5fb94a34829c88183e2bb988"}},"metadata":{}},{"name":"stdout","text":"에폭 [5/5] - 훈련 데이터 손실값 : 0.1033\n에폭 [5/5] - 검증 데이터 손실값 : 0.2204 / 검증 데이터 ROC AUC : 0.9506\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 결과 제출","metadata":{}},{"cell_type":"code","source":"dataset_test = ImageDataset(test, img_dir=img_dir, \n                            transform=transform_test, is_test=True)\nloader_test = DataLoader(dataset_test, batch_size=batch_size, \n                         shuffle=False, worker_init_fn=seed_worker,\n                         generator=g, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2024-09-13T18:10:18.893428Z","iopub.execute_input":"2024-09-13T18:10:18.894184Z","iopub.status.idle":"2024-09-13T18:10:18.900090Z","shell.execute_reply.started":"2024-09-13T18:10:18.894143Z","shell.execute_reply":"2024-09-13T18:10:18.899032Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"model.eval() # 모델을 평가 상태로 설정 \n\npreds = np.zeros((len(test), 4)) # 예측값 저장용 배열 초기화\n\nwith torch.no_grad():\n    for i, images in enumerate(loader_test):\n        images = images.to(device)\n        outputs = model(images)\n        # 타깃 예측 확률 \n        preds_part = torch.softmax(outputs.cpu(), dim=1).squeeze().numpy()\n        preds[i*batch_size:(i+1)*batch_size] += preds_part","metadata":{"execution":{"iopub.status.busy":"2024-09-13T18:10:20.036074Z","iopub.execute_input":"2024-09-13T18:10:20.036926Z","iopub.status.idle":"2024-09-13T18:12:31.037861Z","shell.execute_reply.started":"2024-09-13T18:10:20.036888Z","shell.execute_reply":"2024-09-13T18:12:31.036524Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"submission[['healthy', 'multiple_diseases', 'rust', 'scab']] = preds\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-13T18:12:31.040087Z","iopub.execute_input":"2024-09-13T18:12:31.040453Z","iopub.status.idle":"2024-09-13T18:12:31.071073Z","shell.execute_reply.started":"2024-09-13T18:12:31.040416Z","shell.execute_reply":"2024-09-13T18:12:31.070177Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}